{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 03: Regression, Learning Curves and Regularization\n",
    "\n",
    "**Due Date:** Friday 10/04/2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please fill these in before submitting, just in case I accidentally mix up file names while grading**:\n",
    "\n",
    "Name: Joe Student\n",
    "\n",
    "CWID-5: (Last 5 digits of cwid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "In this exercise we will be using what you have learned about linear regression, polynomial regression and\n",
    "regularization, to explore an artificial dataset.\n",
    "\n",
    "I have generated a secret dataset.  The dataset uses a polynomial combination of a single parameter.\n",
    "The unknown function is no less than degree 2, but no more than a degree 20 polynomial.  And some random\n",
    "noise has also been added into the function, so that fitting it is not a completely trivial or obvious\n",
    "exercise.  Since the dataset is generated from a polynomial function, the output labels `y` are\n",
    "real valued numbers.  And thus you will be performing a regression fitting task in this assignment.\n",
    "\n",
    "Your task, should you choose to accept it, is to load and explore the data from this function.  Your ultimate\n",
    "goal is to try your best to determine the degree of the polynomial used, and the values of the parameters\n",
    "then used in the secret function.  Because of the noise added to the data you are given, you will not be able\n",
    "to exactly recover the parameters used to generate the artificial data.  You will even find that determining the\n",
    "exact degree of the generating polynomial function is not possible.  How you apply polynomial fitting and \n",
    "regularization techniques can give different and better or worse approximations of the true underlying function.\n",
    "\n",
    "In the below cells, I give instructions for the tasks you should attempt.  You will need to load the data and\n",
    "visualize it to begin with.  Then you will be asked to apply polynomial fitting and regularization in an attempt\n",
    "to fit the data.  But ultimately, at the end, you should keep in mind that there is a true function of some\n",
    "unknown polynomial degree with some coefficient settings used.  You will later be able to see what the\n",
    "true function was and compare your model performance to the true function you are exploring in this\n",
    "exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following ipython magic will reload changed file/modules.\n",
    "# So when editing function in source code modules, you should\n",
    "# be able to just rerun the cell, not restart the whole kernel.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# By convention, we often just import the specific classes/functions\n",
    "# from scikit-learn we will need to train a model and perform prediction.\n",
    "# Here we include all of the classes and functions you should need for this\n",
    "# assignment from the sklearn library, but there could be other methods you might\n",
    "# want to try or would be useful to the way you approach the problem, so feel free\n",
    "# to import others you might need or want to try\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions/moduls from this project.  We manually set the\n",
    "# PYTHONPATH to append the location to search for this assignments\n",
    "# functions to just ensure the imports are found\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "# assignment function imports for doctests and github autograding\n",
    "# these are required for assignment autograding\n",
    "from assg_utils import run_unittests, run_doctests\n",
    "from assg_tasks import task1_load_data, task2_underfit_model, learning_curve_errors, task4_overfit_model, task5_lasso_model, task6_ridge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook wide settings to make plots more readable and visually better to understand\n",
    "np.set_printoptions(suppress=True)\n",
    "plt.rc('axes', labelsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rc('figure', titlesize=18)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0) # default figure size if not specified in plot\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Load Data, Explore and Visualize\n",
    "------------\n",
    "\n",
    "You have been given a set of 100 (artificial) data points in the file named `assg-03-data.csv` in our \n",
    "data subdirectory.  Start by loading this file into a pandas dataframe.  Explore the data a bit.\n",
    "Use the `describe()` function to get a sense of the number of values (there should be `m=100` samples),\n",
    "and their mean and variance.  There are 2 columns, where `x` is the feature, and `y` is the function\n",
    "value.  Or in other words 'y' is the label we will use for the regression fitting task.  What is the range of\n",
    "the `x` features?  What is the range of the `y` output label here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and describe and explore a bit here before doing first task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment you will need to create a function that loads this data and creates two numpy arrays.\n",
    "Write/complete the function in `src/assg_tasks.py` named `task1_load_data()`.  This function should\n",
    "simply load the data from the file, as you did above.  It should extract the `x` features into\n",
    "a numpy array.  This array needs to be a 2-d column array (so it should be shaped (100,1)).  Likewise\n",
    "you should extract the regression labels into a numpy array, though the target regression labels should\n",
    "be returned as a 1-d vector with 100 elements in it.  Your `x` and `y` arrays should be returned\n",
    "from this function as a result of calling it.\n",
    "\n",
    "Do not modify or remove the following cell.  When your function correctly loads and returns the\n",
    "expected feature array `x` and target labels `y`, the following cell should run and pass\n",
    "the tests for your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_loaded_types (test_assg_tasks.test_task1_load_data.test_loaded_types)\n",
      "test_loaded_types ... ok\n",
      "test_x_properties (test_assg_tasks.test_task1_load_data.test_x_properties)\n",
      "test_x_properties ... FAIL\n",
      "test_y_properties (test_assg_tasks.test_task1_load_data.test_y_properties)\n",
      "test_y_properties ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_x_properties (test_assg_tasks.test_task1_load_data.test_x_properties)\n",
      "test_x_properties\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 24, in test_x_properties\n",
      "    self.assertEqual(self.x.shape, (100, 1))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 444, in assertEqual\n",
      "    super().assertEqual(first, second, msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 885, in assertEqual\n",
      "    assertion_func(first, second, msg=msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1102, in assertTupleEqual\n",
      "    self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1073, in assertSequenceEqual\n",
      "    self.fail(msg)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: Tuples differ: (1,) != (100, 1)\n",
      "\n",
      "First differing element 0:\n",
      "1\n",
      "100\n",
      "\n",
      "Second tuple contains 1 additional elements.\n",
      "First extra element 1:\n",
      "1\n",
      "\n",
      "- (1,)\n",
      "+ (100, 1)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_y_properties (test_assg_tasks.test_task1_load_data.test_y_properties)\n",
      "test_y_properties\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 27, in test_y_properties\n",
      "    self.assertEqual(self.y.shape, (100,))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 444, in assertEqual\n",
      "    super().assertEqual(first, second, msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 885, in assertEqual\n",
      "    assertion_func(first, second, msg=msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1102, in assertTupleEqual\n",
      "    self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1073, in assertSequenceEqual\n",
      "    self.fail(msg)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: Tuples differ: (1,) != (100,)\n",
      "\n",
      "First differing element 0:\n",
      "1\n",
      "100\n",
      "\n",
      "- (1,)\n",
      "+ (100,)\n",
      "?   ++\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.195s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=2>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "x, y = task1_load_data()\n",
    "run_unittests(['test_task1_load_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally before moving on, create a scatter plot of the data that you are using in this assignment\n",
    "in the following cell.  Make sure you are using a scatter plot, since this is raw data and\n",
    "not a model.  You should label your axis on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data we loaded here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Task 2: Create an Underfit Model\n",
    "\n",
    "The degree of the secret function is more than 2, but probably less than 20 in this assignment.  Lets create a model\n",
    "that should underfit the data.  You will create a degree 2 (quadratic) model.  Underfit a degree 2 polynomial regression to the\n",
    "data.  \n",
    "\n",
    "You should complete the function in `src/asst_tasks.py` named `task2_underfit_model()` before\n",
    "running the next cell to test your work.  This function takes the `x` input features and\n",
    "`y` target labels as input, which should have been created successfully in the previous task.\n",
    "\n",
    "Do the following to create a model\n",
    "- Create a `scikit-learn` pipeline.\n",
    "- The first step in the pipeline should be a `PolynomialFeatures` transformer that transforms the input features\n",
    "  to a degree 2 polynomial.  You should not generate the bias terms from this transformer, as the linear regression\n",
    "  model you will use does not expect a dummy input feature in the input feature data.\n",
    "- Then for the second step have a standard `scikit-learn` `LinearRegression` model.  You should not specify any\n",
    "  meta parameters for this underfit model, use all of the `scikit-learn` default settings for a linear regression.\n",
    "\n",
    "Do not modify or remove the following code cell.  If you create your underfit model pipeline correctly, the\n",
    "tests of your work in the next cell should all pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_coef (test_assg_tasks.test_task2_underfit_model.test_coef)\n",
      "test_coef ... ERROR\n",
      "test_intercept (test_assg_tasks.test_task2_underfit_model.test_intercept)\n",
      "test_intercept ... ERROR\n",
      "test_model_pipeline (test_assg_tasks.test_task2_underfit_model.test_model_pipeline)\n",
      "test_model_pipeline ... FAIL\n",
      "test_r2score (test_assg_tasks.test_task2_underfit_model.test_r2score)\n",
      "test_r2score ... ERROR\n",
      "test_rmse (test_assg_tasks.test_task2_underfit_model.test_rmse)\n",
      "test_rmse ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_coef (test_assg_tasks.test_task2_underfit_model.test_coef)\n",
      "test_coef\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 51, in test_coef\n",
      "    coef = self.model[1].coef_\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_intercept (test_assg_tasks.test_task2_underfit_model.test_intercept)\n",
      "test_intercept\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 47, in test_intercept\n",
      "    intercept = self.model[1].intercept_\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_r2score (test_assg_tasks.test_task2_underfit_model.test_r2score)\n",
      "test_r2score\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 56, in test_r2score\n",
      "    r2score = self.model.score(self.x, self.y)\n",
      "AttributeError: 'NoneType' object has no attribute 'score'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_rmse (test_assg_tasks.test_task2_underfit_model.test_rmse)\n",
      "test_rmse\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 60, in test_rmse\n",
      "    y_predict = self.model.predict(self.x)\n",
      "AttributeError: 'NoneType' object has no attribute 'predict'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_model_pipeline (test_assg_tasks.test_task2_underfit_model.test_model_pipeline)\n",
      "test_model_pipeline\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 35, in test_model_pipeline\n",
      "    self.assertIsInstance(self.model, sklearn.pipeline.Pipeline)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 666, in assertIsInstance\n",
      "    self.fail(f\"{instance!r} is not an instance of {classOrTuple}{suffix}\")\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: None is not an instance of <class 'sklearn.pipeline.Pipeline'>\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.020s\n",
      "\n",
      "FAILED (failures=1, errors=4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=5 errors=4 failures=1>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "underfit_model = task2_underfit_model(x, y)\n",
    "run_unittests(['test_task2_underfit_model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, use introspection of your fitted (pipeline) model to display the intercept and fitted\n",
    "coeffecients of the model.  Also determine the final RMSE and $R^2$ score of the fit.  Display them\n",
    "in the next cell(s) for future reference and discussion.\n",
    "\n",
    "You should get a single intercept parameter.  Since you are underfitting a degree 2 model here, you should\n",
    "expect 2 coefficients, one for the $x^1$ original feature term, and another for the generated\n",
    "$x^2$ square term for your model.\n",
    "\n",
    "Make note of the $R^2$ score, and especially the RMSE fit of your model here.  Do you expect the\n",
    "undefit model to be a good model or a bad model of this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display asked for model parameters and scores here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Calculate and Display Learning Curves\n",
    "\n",
    "Before moving on we need to evaluate how well the model is performing.  To do this you are first going to write a function\n",
    "that will calculate train and test errors of your model, so that we can plot the learning curves of this and all of the other\n",
    "models you build in this assignment.\n",
    "\n",
    "Write the function named `learning_curve_errors()`. This function is in the `src/assg_tasks.py` file of this\n",
    "assignment. \n",
    "\n",
    "The function takes a model (pipeline) and the `x` input features and `y` regression labels as input.  To calculate\n",
    "the learning curve errors, you first need to split the data using an 80/20 train/test split.  Then you are going\n",
    "to train the model with the training data.  You will first train the modle using only 1 of the training inputs.\n",
    "The model will be evaluated on the data point it was trained with, and then on the test data.  Then you will train\n",
    "a model with 2 data points and calculate the errors, and so on until you have trained a model on all of the\n",
    "training data.  For each model from 1, 2 up to all of the training data, you will calculate the RMSE error on\n",
    "from the model on the data you just trained it with, and also the RMSE error on the 20% test data you held back\n",
    "at the start.\n",
    "\n",
    "So to complete this function, perform the following steps in the `learning_curve_errors()` function:\n",
    "\n",
    "1. Split the `x` `y` data you are given in the function into 80% training data and 20% test data.  Use\n",
    "   the appropriate `sckit-learn` function to perform this split, don't do it by hand.\n",
    "2. You will need to return the accumulated train and test errors, so create empty Python lists or numpy\n",
    "   arrays to accumulate and return the errors as you calculate them.\n",
    "3. You need a loop that trains/fits a model then calculates the RMSE error on the data trained with and\n",
    "   on the held back test data.\n",
    "   - Train with 1, 2, 3, ..., all of the train data in the loop\n",
    "   - Evaluate the error on the training data (make sure you only evaluate on the data you trained with, not\n",
    "     all of the training data.\n",
    "   - Evaluate the error on the 20% held back test data.\n",
    "   - Append both of these to the array/list you accumulate of the train and test errors\n",
    "4. This function should return the calculated lists of training errors and test errors.\n",
    "\n",
    "You should not remove or modify the following code cell(s), which will test that your implementation of\n",
    "the `learning_curve_errors()` function is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_test_errors (test_assg_tasks.test_learning_curve_errors.test_test_errors)\n",
      "test_test_errors ... FAIL\n",
      "test_train_errors (test_assg_tasks.test_learning_curve_errors.test_train_errors)\n",
      "test_train_errors ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_test_errors (test_assg_tasks.test_learning_curve_errors.test_test_errors)\n",
      "test_test_errors\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 80, in test_test_errors\n",
      "    self.assertEqual(len(self.test_errors), 79)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 444, in assertEqual\n",
      "    super().assertEqual(first, second, msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 885, in assertEqual\n",
      "    assertion_func(first, second, msg=msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 878, in _baseAssertEqual\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: 0 != 79\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_train_errors (test_assg_tasks.test_learning_curve_errors.test_train_errors)\n",
      "test_train_errors\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 74, in test_train_errors\n",
      "    self.assertEqual(len(self.train_errors), 79)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 444, in assertEqual\n",
      "    super().assertEqual(first, second, msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 885, in assertEqual\n",
      "    assertion_func(first, second, msg=msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 878, in _baseAssertEqual\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: 0 != 79\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.007s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=2>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "run_unittests(['test_learning_curve_errors'])\n",
    "#run_doctests(learning_curve_errors, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to plot the learning curves for your underfit model on all of the\n",
    "data you have.\n",
    "\n",
    "1. You should call your `learning_curve_errors()` function on your underfit model, and the `x` inputs and `y` labels.\n",
    "   You will need to keep the returned train and test errors.\n",
    "2. Before calling the function to generate the learning curve errors, set the NumPy random seed to 42.  If you do this\n",
    "   you will always get the same train/validation split of data when the function is called.  If you do this you\n",
    "   should see that performance converges for train and validation RMSE after using around only 10 data points or so.\n",
    "3. Plot your train and test errors on the same figure.  Label the axis appropriately, and use a legend in your figure\n",
    "   to identify which curve is the training error and which is the testing error.  You should use lines for both\n",
    "   of these curves on this figure.  Make sure you cn see where these converge on the figure, you may need to limit the\n",
    "   y axis to be able to see and read this from your figure.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call your learning_curve_errors() function to the the test and train errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the resulting learning curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want or need to limit the y axis to better view the learning curves.  You should see a\n",
    "bit of a gap usually (because of random split in the learning curves function, results will\n",
    "vary each time you run).  But usually with a training set size of 20 points or so you should find that\n",
    "results converge.  Note the RMSE that you are getting on the training and validation data once they\n",
    "converge on the underfit model.\n",
    "\n",
    "Recall from our discussion in class, that the RMSE obtained on an underfit model does give you some information.\n",
    "We would hope that if we can find a model with the right power, that the validation results will still converge\n",
    "relatively quickly, but with better overall RMSE performance than the underfit model can obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Create an Overfit Model\n",
    "\n",
    "The next step when trying to determine what we can achieve with a type of ML model is to try and\n",
    "overfit the data with a too powerful model.\n",
    "\n",
    "Repeat the previous steps, but with a degree 100 polynomial.  This should be many times larger than the\n",
    "actual degree of the polynomial used in the secret function for this assignment.\n",
    "\n",
    "Do all of the previous steps again for a degree 100 model in the following cells.\n",
    "\n",
    "1. Implement the function named `task4_overfit_model()` in the `src/assg_tasks.py` file.  In this function you need to:\n",
    "   - Create a pipeline to generate degree 100 features that feeds into a default `LinearRegression` model.\n",
    "   - Fit the model to all of the data given as input to the function.\n",
    "   - Return the trained overfit model for testing.\n",
    "\n",
    "Do not modify or remove the following code cell.  If your model performs as expected, you should\n",
    "pass the tests performed on your model in the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_coef (test_assg_tasks.test_task4_overfit_model.test_coef)\n",
      "test_coef ... ERROR\n",
      "test_intercept (test_assg_tasks.test_task4_overfit_model.test_intercept)\n",
      "test_intercept ... ERROR\n",
      "test_model_pipeline (test_assg_tasks.test_task4_overfit_model.test_model_pipeline)\n",
      "test_model_pipeline ... FAIL\n",
      "test_r2score (test_assg_tasks.test_task4_overfit_model.test_r2score)\n",
      "test_r2score ... ERROR\n",
      "test_rmse (test_assg_tasks.test_task4_overfit_model.test_rmse)\n",
      "test_rmse ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_coef (test_assg_tasks.test_task4_overfit_model.test_coef)\n",
      "test_coef\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 107, in test_coef\n",
      "    coef = self.model[1].coef_\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_intercept (test_assg_tasks.test_task4_overfit_model.test_intercept)\n",
      "test_intercept\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 103, in test_intercept\n",
      "    intercept = self.model[1].intercept_\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_r2score (test_assg_tasks.test_task4_overfit_model.test_r2score)\n",
      "test_r2score\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 116, in test_r2score\n",
      "    r2score = self.model.score(self.x, self.y)\n",
      "AttributeError: 'NoneType' object has no attribute 'score'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_rmse (test_assg_tasks.test_task4_overfit_model.test_rmse)\n",
      "test_rmse\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 120, in test_rmse\n",
      "    y_predict = self.model.predict(self.x)\n",
      "AttributeError: 'NoneType' object has no attribute 'predict'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_model_pipeline (test_assg_tasks.test_task4_overfit_model.test_model_pipeline)\n",
      "test_model_pipeline\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 91, in test_model_pipeline\n",
      "    self.assertIsInstance(self.model, sklearn.pipeline.Pipeline)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 666, in assertIsInstance\n",
      "    self.fail(f\"{instance!r} is not an instance of {classOrTuple}{suffix}\")\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: None is not an instance of <class 'sklearn.pipeline.Pipeline'>\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.014s\n",
      "\n",
      "FAILED (failures=1, errors=4)\n"
     ]
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "overfit_model = task4_overfit_model(x, y)\n",
    "run_unittests(['test_task4_overfit_model']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your overfit model is working, do the following\n",
    "\n",
    "1. Report the intercept and slope coefficients for the model.  There should be consideradbly more coefficients this\n",
    "   time around for your overfit model.\n",
    "2. Report $R^2$ and RMSE scores obtained by this overfit model.\n",
    "3. Plot the learning curves of the overfit model.  You should reuse your task 2 function to generate the\n",
    "   learning curve errors to be plotted.  Make sure you set the random seed to 42 again before generating\n",
    "   the learning curve errors.  Also make sure you limit the y axis if needed to be able to see where\n",
    "   if the model converges and what error level the train error settles at.\n",
    "\n",
    "You may want to stop and compare the results of the underfit and overfit model.  What od you notice about\n",
    "the $R^2$ score?  What about the RMSE error reported?  What do you notice about the coefficient values\n",
    "that were fit for the two models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report the fitted model parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally generate the learning curves for the overfit model.  Set the\n",
    "# random seed to 42 before plotting learning curves again.  And\n",
    "# limit y axis if needed to be able to see where curves converge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the resulting learning curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Estimate True Function Degree using Lasso Regularization\n",
    "\n",
    "The Lasso Regularization that we discussed in class (using absolute value for the regularization term,\n",
    "also known as $\\ell_1$ regularization), has the effect of driving unneeded parameters to 0.  So in our current\n",
    "assignment, it can give us some insight into the true degree of the secret function polynomial used to\n",
    "generate the data you were given.\n",
    "\n",
    "In the following cell, use Lasso regularization on the degree 100 model again.  Try exploring values\n",
    "of alpha used in your Lasso regularization model.  Your goal is to find a value of alpha\n",
    "that will achieve an RMSE on your fitted model much better than the underfit RMSE and hopefully approaching the overfit\n",
    "model error.  You probably won't be able to get quite the same RMSE, but you should be able to\n",
    "find values of `alpha` that are much better than the underfit model achieves.\n",
    "\n",
    "Do all of the previous steps again for a Lasso regularization model in the following cells.  As before, your actual code needs to\n",
    "go into the `task5_lasso_model()` function in the `src/assg_tasks.py` file.\n",
    "\n",
    "1. Create a pipeline to generate degree 100 features for a `Lasso` regression model.\n",
    "2. Fit the Lasso regularized pipeline model to all of the data, exploring good values of `alpha` to use for the regularization.\n",
    "\n",
    "Do not remove or modify the following code cell line.  It will test that you create a `Lasso` model\n",
    "as expected, and that it gets a reasonable fit on the data.  Your model will be tested to see that\n",
    "it meets reasonable expectations for this task by the unit tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_coef (test_assg_tasks.test_task5_lasso_model.test_coef)\n",
      "test_coef ... ERROR\n",
      "test_model_pipeline (test_assg_tasks.test_task5_lasso_model.test_model_pipeline)\n",
      "test_model_pipeline ... FAIL\n",
      "test_r2score (test_assg_tasks.test_task5_lasso_model.test_r2score)\n",
      "test_r2score ... ERROR\n",
      "test_rmse (test_assg_tasks.test_task5_lasso_model.test_rmse)\n",
      "test_rmse ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_coef (test_assg_tasks.test_task5_lasso_model.test_coef)\n",
      "test_coef\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 141, in test_coef\n",
      "    coef = self.model[1].coef_\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_r2score (test_assg_tasks.test_task5_lasso_model.test_r2score)\n",
      "test_r2score\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 145, in test_r2score\n",
      "    r2score = self.model.score(self.x, self.y)\n",
      "AttributeError: 'NoneType' object has no attribute 'score'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_rmse (test_assg_tasks.test_task5_lasso_model.test_rmse)\n",
      "test_rmse\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 149, in test_rmse\n",
      "    y_predict = self.model.predict(self.x)\n",
      "AttributeError: 'NoneType' object has no attribute 'predict'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_model_pipeline (test_assg_tasks.test_task5_lasso_model.test_model_pipeline)\n",
      "test_model_pipeline\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 130, in test_model_pipeline\n",
      "    self.assertIsInstance(self.model, sklearn.pipeline.Pipeline)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 666, in assertIsInstance\n",
      "    self.fail(f\"{instance!r} is not an instance of {classOrTuple}{suffix}\")\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: None is not an instance of <class 'sklearn.pipeline.Pipeline'>\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.013s\n",
      "\n",
      "FAILED (failures=1, errors=3)\n"
     ]
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "lasso_model = task5_lasso_model(x, y)\n",
    "run_unittests(['test_task5_lasso_model']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then as before, do the following with the returned fitted `Lasso` model:\n",
    "\n",
    "1. Report the intercept and slope coefficients for the model. Note which parameters have been driven to 0 by the\n",
    "   Lasso regularization.\n",
    "2. Report $R^2$ and RMSE scores obtained by this Lasso regularized model.\n",
    "3. Plot the learning curves of the Lasso regularized model.  Reuse your `learning_curve_errors()` function.\n",
    "   Make sure that you set the random seed to 42 before calculating the learning curve errors, and that\n",
    "   you plot the learning curves the same as before so that it is apparent if the model is underfitting,\n",
    "   overfitting or converging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report the model coefficients and scores for the lasso regularization model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally generate the learning curve errors for the lasso regularization\n",
    "# model.  Set the random seed to 42 before plotting learning curves\n",
    "# again.  And limit y axis if needed to be able to see where curves\n",
    "# converge.  You will probably get ConvergenceWarnings here, though you\n",
    "# may want to and probably should increase the `max_iter` for you model\n",
    "# to reduce these warnings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the resulting learning curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will know you are getting somewhere in the appropriate neighborhood for good\n",
    "values of the `alpha` metaparameter when:\n",
    "\n",
    "1. Your R^2 and RMSE scores are similar to the overfit model, and are certainly better than the underfit model.\n",
    "2. The learning curves should \"converge\" again here, similar to the underfit model.  Probably sometime after using\n",
    "   20 or 30 data points in the training set size.  But they should converge to an RMSE lower than that seen for\n",
    "   the underfit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Use Ridge regularization\n",
    "\n",
    "Try and at least match, if not improve upon, the best RMSE you can find from Lasso regularization using\n",
    "Ridge regularization instead.  You should find that coefficients will not mostly be driven to 0's like\n",
    "before for the Lasso regularization. But you may be more easily able to find an alpha that gets an improvement\n",
    "in terms of RMSE over what you can obtain with the Lasso model.\n",
    "\n",
    "Again perform all of the following for a Ridge regularization model, finding an appropriate value of the `alpha`\n",
    "meta parameter.  The function where you implement your Ridge model is in the `task6_ridge_model()` function\n",
    "in the `src/assg_tasks.py` file.\n",
    "\n",
    "1. Create a pipeline to generate degree 100 features for a `Ridge` regression model.\n",
    "2. Fit the Ridge regularized model pipeline to all of the data, exploring good values of `alpha` to use for the regularization.\n",
    "3. Report the intercept and slope coefficients for the model. Note that most parameters are not 0 for this type of regularization.\n",
    "5. Report $R^2$ and RMSE scores obtained by this Ridge regularized model.\n",
    "6. Plot the learning curves of the Ridge regularized model.\n",
    "\n",
    "As usual make sure you do not remove or change the following cell that tests your creating of the\n",
    "Ridge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_coef (test_assg_tasks.test_task6_ridge_model.test_coef)\n",
      "test_coef ... ERROR\n",
      "test_model_pipeline (test_assg_tasks.test_task6_ridge_model.test_model_pipeline)\n",
      "test_model_pipeline ... FAIL\n",
      "test_r2score (test_assg_tasks.test_task6_ridge_model.test_r2score)\n",
      "test_r2score ... ERROR\n",
      "test_rmse (test_assg_tasks.test_task6_ridge_model.test_rmse)\n",
      "test_rmse ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_coef (test_assg_tasks.test_task6_ridge_model.test_coef)\n",
      "test_coef\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 170, in test_coef\n",
      "    coef = self.model[1].coef_\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_r2score (test_assg_tasks.test_task6_ridge_model.test_r2score)\n",
      "test_r2score\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 174, in test_r2score\n",
      "    r2score = self.model.score(self.x, self.y)\n",
      "AttributeError: 'NoneType' object has no attribute 'score'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_rmse (test_assg_tasks.test_task6_ridge_model.test_rmse)\n",
      "test_rmse\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 178, in test_rmse\n",
      "    y_predict = self.model.predict(self.x)\n",
      "AttributeError: 'NoneType' object has no attribute 'predict'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_model_pipeline (test_assg_tasks.test_task6_ridge_model.test_model_pipeline)\n",
      "test_model_pipeline\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg03/notebooks/../src/test_assg_tasks.py\", line 159, in test_model_pipeline\n",
      "    self.assertIsInstance(self.model, sklearn.pipeline.Pipeline)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 666, in assertIsInstance\n",
      "    self.fail(f\"{instance!r} is not an instance of {classOrTuple}{suffix}\")\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: None is not an instance of <class 'sklearn.pipeline.Pipeline'>\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.017s\n",
      "\n",
      "FAILED (failures=1, errors=3)\n"
     ]
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "ridge_model = task6_ridge_model(x, y)\n",
    "run_unittests(['test_task6_ridge_model']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report model parameters and scores for the lasso regularization model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally generate the learning curves for the lasso regularization\n",
    "# model.  Set the random seed to 42 before plotting learning curves\n",
    "# again.  And limit y axis if needed to be able to see where curves\n",
    "# converge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the resulting learning curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Summary and Discussion of Findings\n",
    "\n",
    "Fill out the following table with the values you obtain in your work on the assignment.\n",
    "\n",
    "| Model    | `alpha` | $R^2$  | RMSE   |\n",
    "|----------|---------|--------|--------|\n",
    "| underfit | none    | 0.0000 | 0.0000 | \n",
    "| overfit  | none    | 0.0000 | 0.0000 |\n",
    "| Lasso    | 0.0000  | 0.0000 | 0.0000 |\n",
    "| Lasso    | 1.0000  | 0.0000 | 0.0000 |\n",
    "| Lasso    | 2.0000  | 0.0000 | 0.0000 |\n",
    "| Ridge    | 0.0000  | 0.0000 | 0.0000 |\n",
    "| Ridge    | 1.0000  | 0.0000 | 0.0000 |\n",
    "| Ridge    | 2.0000  | 0.0000 | 0.0000 |\n",
    "\n",
    "I would like to see at least 3 different values each for your Lasso and Ridge models.  \n",
    "\n",
    "For the first Lasso regularization model, try and find an `alpha` that gets the lowest\n",
    "RMSE that you can, and also drives as many of the coefficients to 0 as you can.  This can give\n",
    "you an approximate estimate of the degree of the secret polynomial function you are trying to model.\n",
    "Show a value that is larger than this `alpha` (more regularization), that drives even more parameters\n",
    "to 0, but probably increases the RMSE error.  Also show a value with smaller `alpha`, that probably\n",
    "is overfitting a bit, so you get the same RMSE, but maybe many or all of the coefficients are still non zero.\n",
    "\n",
    "For the Ridge regression, for the secret function given in this assignment you will probably find that you\n",
    "can get better RMSE than you can for LASSO.  Again try and find the value for the `alpha` amount of\n",
    "regularization to Ridge that gives the minimum RMSE you can get, but doesn't seem to be overfitting.  Report\n",
    "on a value of `alpha` bigger than this (more regularization) that seems to start to underfit so that the RMSE\n",
    "goes up.  And also on a value smaller than the best you can find, so that you may be overfitting.\n",
    "\n",
    "Once you have filled out the above table, please discuss your observations about the underfit, overfit,\n",
    "Lasso and Ridge models that you have obsreved.  Your discussion must be in this markdown cell, in the\n",
    "section marked `Discussion` below.  You should make observations on what the coefficients look like for the \n",
    "various models you fit.  You should give an estimate from your Lasso regression on what the degree of the\n",
    "polynomial seems to be from your testing of alpha to find a model with the lowest RMSE that drives as many\n",
    "coefficients to 0 as possible.  \n",
    "\n",
    "\n",
    "### Discussion\n",
    "\n",
    "Place your discussion here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: More Systematic Grid Meta-Parameter Search\n",
    "\n",
    "While it is possible (and useful) to get a feel for what meta-parameter values you need to obtain\n",
    "good results from regularization and different models, at times we need to be more systematic.\n",
    "\n",
    "You have seen some examples of using the Scikit-learn grid search to more systematically\n",
    "explore model meta parameters.  The following is a tutorial specifically for beginners\n",
    "on using [scikit-learn GridSearchCV for Beginners](https://towardsdatascience.com/gridsearchcv-for-beginners-db48a90114ee)\n",
    "that you might find helpeful to look at as well when doing this section.\n",
    "\n",
    "In the following, perform a more systematic grid search of the alpha parameter for a Lasso\n",
    "regression using a degree 100 polynomial as input.  Report the RMSE performance of\n",
    "the best model you find.  Make sure you search a fairly good range of `alpha` parameters.\n",
    "Also report the intercept and coefficients of the model.\n",
    "\n",
    "Did the best model have a similar `alpha` value that you got trying to tune it by hand?  Do the\n",
    "parameters that were driven to 0 look similar or different from the value of `alpha` you found\n",
    "previously?  For extra consideration, create a plot to visualize the RMSE performance for the range of\n",
    "`alpha` values that you explored in the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid search of Lasso/l1 over alpha parameter space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to perform the grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the best parameter you found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report intercept and slope coefficients for the lasso regularization model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report R^2 and RMSE performance of the lasso regularization model on all of the data here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize performance as a function of the alpha regularization parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final activity for this assignment, below you have been given an example of a setup for a\n",
    "`GridSearchCV` that will instead search all polynomial degrees from 2 to 100.  Modify the following \n",
    "code if necessary to run in your assignment (may need to change name of input `x` or output `y` or\n",
    "other minor tweaks?)  Observe the polynomial degree obtained by this grid search on the data.  Does\n",
    "that surprise your, or look resonable to some of the estimates you have made about the secret\n",
    "function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function.  This returns a fit/transformer pipeline, as GridSearchCV expects\n",
    "# but we can call it to generate pipelines with different degree polynomials\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree, include_bias=False), LinearRegression(**kwargs))\n",
    "\n",
    "# we set up grid search on single degree meta-parameter of the PolynomialFeatures part of the pipeline\n",
    "# the result is that degrees from 1 to 100 are tried for PolynomialFeatures here\n",
    "degrees = np.arange(2, 100)\n",
    "parameters = {'polynomialfeatures__degree': degrees}\n",
    "\n",
    "# the grid search over the polynomial degrees on standard Linear Regression\n",
    "poly_gridcv = GridSearchCV(PolynomialRegression(), parameters, scoring='neg_mean_squared_error', cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to perform the grid search\n",
    "#poly_gridcv.fit(x, y)\n",
    "\n",
    "# display the best parameter we found\n",
    "#print('Grid search best alpha parameter:', poly_gridcv.best_params_)\n",
    "#print('Grid search best MSE: ', poly_gridcv.best_score_)\n",
    "#print('Grid search best RMSE: ', np.sqrt(-poly_gridcv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report intercept and slope coefficients for the lasso regularization model\n",
    "#print('Intercept   : ', poly_gridcv.best_estimator_['linearregression'].intercept_)\n",
    "#print('Coefficients: ', poly_gridcv.best_estimator_['linearregression'].coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
